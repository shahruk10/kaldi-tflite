#!/usr/bin/env python3

# Copyright (2021-) Shahruk Hossain <shahruk10@gmail.com>
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.
# ==============================================================================



import os
import numpy as np

from kaldi_tflite.lib.io import KaldiNnet3Reader

class RefTdnnSingleLayer:

    # Layer config.
    cfg = {
        "units": 32,
        "context": [-3, -1, 0, 1],
        "subsampling_factor": 1,
        "padding": "SAME",
        "activation": "relu",
        "use_bias": True,
    }

    # Layer Parameters.
    mdl = KaldiNnet3Reader("kaldi_tflite/lib/testdata/tdnn/src/tdnn_single_layer/final.raw", True) 

    # Dummy input.
    inputs = np.float32([
        0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 0.10, 0.11, 0.12, 0.13, 0.14, 0.15, 0.16, 0.17, 0.18, 0.19, 0.20, 0.21, 0.22, 0.23, 0.24, 0.25, 0.26, 0.27, 0.28, 0.29, 0.30, 
        0.2, 0.4, 0.6, 0.8, 0.10, 0.12, 0.14, 0.16, 0.18, 0.20, 0.22, 0.24, 0.26, 0.28, 0.30, 0.32, 0.34, 0.36, 0.38, 0.40, 0.42, 0.44, 0.46, 0.48, 0.50, 0.52, 0.54, 0.56, 0.58, 0.60, 
        0.3, 0.6, 0.9, 0.12, 0.15, 0.18, 0.21, 0.24, 0.27, 0.30, 0.33, 0.36, 0.39, 0.42, 0.45, 0.48, 0.51, 0.54, 0.57, 0.60, 0.63, 0.66, 0.69, 0.72, 0.75, 0.78, 0.81, 0.84, 0.87, 0.90, 
        0.4, 0.8, 0.12, 0.16, 0.20, 0.24, 0.28, 0.32, 0.36, 0.40, 0.44, 0.48, 0.52, 0.56, 0.60, 0.64, 0.68, 0.72, 0.76, 0.80, 0.84, 0.88, 0.92, 0.96, 0.100, 0.104, 0.108, 0.112, 0.116, 0.120, 
        0.5, 0.10, 0.15, 0.20, 0.25, 0.30, 0.35, 0.40, 0.45, 0.50, 0.55, 0.60, 0.65, 0.70, 0.75, 0.80, 0.85, 0.90, 0.95, 0.100, 0.105, 0.110, 0.115, 0.120, 0.125, 0.130, 0.135, 0.140, 0.145, 0.150, 
        0.6, 0.12, 0.18, 0.24, 0.30, 0.36, 0.42, 0.48, 0.54, 0.60, 0.66, 0.72, 0.78, 0.84, 0.90, 0.96, 0.102, 0.108, 0.114, 0.120, 0.126, 0.132, 0.138, 0.144, 0.150, 0.156, 0.162, 0.168, 0.174, 0.180, 
        0.7, 0.14, 0.21, 0.28, 0.35, 0.42, 0.49, 0.56, 0.63, 0.70, 0.77, 0.84, 0.91, 0.98, 0.105, 0.112, 0.119, 0.126, 0.133, 0.140, 0.147, 0.154, 0.161, 0.168, 0.175, 0.182, 0.189, 0.196, 0.203, 0.210, 
        0.8, 0.16, 0.24, 0.32, 0.40, 0.48, 0.56, 0.64, 0.72, 0.80, 0.88, 0.96, 0.104, 0.112, 0.120, 0.128, 0.136, 0.144, 0.152, 0.160, 0.168, 0.176, 0.184, 0.192, 0.200, 0.208, 0.216, 0.224, 0.232, 0.240, 
    ]).reshape(1, 8, 30)

    # Outputs using dummy input.
    outputs = np.float32([
        0, 0.4740313, 1.547519, 0, 1.109553, 2.207867, 1.530283, 0, 0, 0.8665433, 0.5097063, 1.47771, 0.4428695, 0, 0, 0, 0, 0.5728315, 1.513324, 0, 0, 0.8469793, 0.7672764, 0, 0.566792, 0, 0.3774216, 0, 0.05979365, 0.2538823, 0.0790793, 0.1633957, 
        0, 0.06724226, 1.85676, 0, 1.063604, 2.639375, 1.725131, 0.1059714, 0, 0.7521623, 0.6134143, 1.653236, 0.2026715, 0, 0, 0, 0, 0.763106, 1.609141, 0, 0, 0.8958387, 1.168573, 0, 0.7612857, 0.2267295, 0.4954645, 0, 0.171527, 0.03447768, 0.1876802, 0.2617823, 
        0, 0, 1.881305, 0, 1.251959, 2.562731, 1.574664, 0, 0, 0.9851249, 0.638153, 1.402492, 0.18162, 0, 0, 0, 0, 0.7713188, 1.58885, 0, 0, 0.5744496, 1.520595, 0.2594644, 0.3709328, 0.6627253, 0.5712422, 0, 0.04822347, 0.007405162, 0.1702979, 0, 
        0, 0.02547795, 1.381054, 0, 0.9118004, 2.144598, 1.101625, 0, 0, 0.8376411, 0.9098628, 1.656662, 0.3982766, 0, 0, 0, 0, 0.9075788, 1.50457, 0, 0, 0.1572585, 1.141775, 0, 0.8295531, 0.4157375, 0.5031696, 0, 0, 0.3640782, 0.1587311, 0, 
        0, 0.2251466, 1.815161, 0, 0.6627339, 1.970551, 1.09519, 0, 0, 0.8395101, 0.7667233, 2.022965, 0.08764459, 0, 0, 0, 0, 0.9086046, 1.113468, 0.02642447, 0, 0.98045, 1.860175, 0.1175024, 0.9976023, 0.1620716, 0.6779283, 0.06739244, 0, 0.3285919, 0.1841471, 0.1551478, 
        0, 0.07337305, 1.80716, 0, 0.8289735, 1.495128, 1.026486, 0, 0, 0.6722122, 0.6742829, 2.085456, 0.4859554, 0, 0, 0, 0, 0.4248836, 1.547688, 0.09481794, 0, 1.039961, 1.897108, 0, 0.4605583, 0.3862074, 0.9805456, 0.08563006, 0, 0.03928667, 0.198432, 0, 
        0, 0, 1.704802, 0, 0.7936745, 1.785425, 0.992124, 0.0008981526, 0, 0.9314662, 0.9186477, 2.077178, 0.3561766, 0, 0, 0, 0, 0.5920631, 1.808465, 0.4219291, 0, 1.174265, 1.68945, 0, 0.2890358, 0.4805356, 0.4825943, 0, 0.1819618, 0.3399685, 0, 0.1291766, 
        0, 0, 1.43226, 0, 0.6348414, 1.865733, 1.295195, 0, 0, 1.012808, 1.140066, 2.144258, 0, 0, 0, 0, 0, 0.5668519, 1.407959, 0.607942, 0, 1.323307, 1.656422, 0, 0.3482499, 0.3718704, 0.4737198, 0, 0.04486513, 0.3445513, 0, 0.0506987, 
    ]).reshape(1, 8, 32)

    @classmethod
    def weights(cls) -> dict:
        kernel = cls.mdl.components[0]["params"]
        bias = cls.mdl.components[0]["bias"]
        return (kernel, bias)
