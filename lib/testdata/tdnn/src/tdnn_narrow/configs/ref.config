# This file was created by the command:
# /home/shahruk/git/kaldi/egs/wsj/s5/steps/nnet3/xconfig_to_configs.py --xconfig-file /media/shahruk/terra2x/cobalt2/exp/20211128-plda-in-tensorflow/kaldi-xvector-diarization-tflite/lib/testdata/tdnn/src/tdnn_narrow/configs/network.xconfig --config-dir /media/shahruk/terra2x/cobalt2/exp/20211128-plda-in-tensorflow/kaldi-xvector-diarization-tflite/lib/testdata/tdnn/src/tdnn_narrow/configs/
# It contains the entire neural network, but with those
# components that would normally require fixed vectors/matrices
# read from disk, replaced with random initialization
# (this applies to the LDA-like transform and the
# presoftmax-prior-scale, if applicable).  This file
# is used only to work out the left-context and right-context
# of the network.

input-node name=input dim=3
component name=tdnn1.affine type=NaturalGradientAffineComponent input-dim=15 output-dim=5  max-change=0.75
component-node name=tdnn1.affine component=tdnn1.affine input=Append(Offset(input, -2), Offset(input, -1), input, Offset(input, 1), Offset(input, 2))
component name=tdnn1.relu type=RectifiedLinearComponent dim=5 self-repair-scale=1e-05
component-node name=tdnn1.relu component=tdnn1.relu input=tdnn1.affine
component name=tdnn1.batchnorm type=BatchNormComponent dim=5 target-rms=1.0
component-node name=tdnn1.batchnorm component=tdnn1.batchnorm input=tdnn1.relu
component name=tdnn2.affine type=NaturalGradientAffineComponent input-dim=15 output-dim=8  max-change=0.75
component-node name=tdnn2.affine component=tdnn2.affine input=Append(Offset(tdnn1.batchnorm, -2), tdnn1.batchnorm, Offset(tdnn1.batchnorm, 2))
component name=tdnn2.relu type=RectifiedLinearComponent dim=8 self-repair-scale=1e-05
component-node name=tdnn2.relu component=tdnn2.relu input=tdnn2.affine
component name=tdnn2.batchnorm type=BatchNormComponent dim=8 target-rms=1.0
component-node name=tdnn2.batchnorm component=tdnn2.batchnorm input=tdnn2.relu
component name=tdnn3.affine type=NaturalGradientAffineComponent input-dim=24 output-dim=8  max-change=0.75
component-node name=tdnn3.affine component=tdnn3.affine input=Append(Offset(tdnn2.batchnorm, -3), tdnn2.batchnorm, Offset(tdnn2.batchnorm, 3))
component name=tdnn3.relu type=RectifiedLinearComponent dim=8 self-repair-scale=1e-05
component-node name=tdnn3.relu component=tdnn3.relu input=tdnn3.affine
component name=tdnn3.batchnorm type=BatchNormComponent dim=8 target-rms=1.0
component-node name=tdnn3.batchnorm component=tdnn3.batchnorm input=tdnn3.relu
component name=tdnn4.affine type=NaturalGradientAffineComponent input-dim=8 output-dim=8  max-change=0.75
component-node name=tdnn4.affine component=tdnn4.affine input=tdnn3.batchnorm
component name=tdnn4.relu type=RectifiedLinearComponent dim=8 self-repair-scale=1e-05
component-node name=tdnn4.relu component=tdnn4.relu input=tdnn4.affine
component name=tdnn4.batchnorm type=BatchNormComponent dim=8 target-rms=1.0
component-node name=tdnn4.batchnorm component=tdnn4.batchnorm input=tdnn4.relu
component name=tdnn5.affine type=NaturalGradientAffineComponent input-dim=8 output-dim=8  max-change=0.75
component-node name=tdnn5.affine component=tdnn5.affine input=tdnn4.batchnorm
component name=tdnn5.relu type=RectifiedLinearComponent dim=8 self-repair-scale=1e-05
component-node name=tdnn5.relu component=tdnn5.relu input=tdnn5.affine
component name=tdnn5.batchnorm type=BatchNormComponent dim=8 target-rms=1.0
component-node name=tdnn5.batchnorm component=tdnn5.batchnorm input=tdnn5.relu
component name=output.affine type=NaturalGradientAffineComponent input-dim=8 output-dim=1  max-change=1.5 param-stddev=0.0 bias-stddev=0.0
component-node name=output.affine component=output.affine input=tdnn5.batchnorm
component name=output.log-softmax type=LogSoftmaxComponent dim=1
component-node name=output.log-softmax component=output.log-softmax input=output.affine
output-node name=output input=output.log-softmax objective=linear
